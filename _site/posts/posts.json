[
  {
    "path": "posts/2021-05-26-custom-syntax-highlighting-for-distill-part-2-creating-the-palette/",
    "title": "Custom Syntax Highlighting for {distill} Part 2: Creating the Palette",
    "description": "How to create an appealing and accessible colour palette for a syntax highlighting scheme",
    "author": [
      {
        "name": "Ella Kaye",
        "url": "https://twitter.com/ellamkaye"
      }
    ],
    "date": "2021-05-26",
    "categories": [
      "distill",
      "colour",
      "accessibility"
    ],
    "contents": "\n\nContents\nPart 1 recap and Part 2 overview\nA brief primer on colour theory\nColour harmonies\nColour spaces\n\nApproach 1: ColorSlurp and HSB\nBuilding a palette based on my pink, using colour theory\nAdapting for web accessibility\nChecking for colourblindness\n\nApproach 2: An R-based HCL alternative\nBuilding a palette based on my pink, using colour theory\nAdapting for web accessibility\nChecking for colourblindness\nBut, do I like it?\n\nBack to Part 1\n\n\n\n\nPart 1 recap and Part 2 overview\nIn Part 1 of this series, custom syntax highlighting for {distill}: modifying the theme, I describe how and why I went about the process of finding and modifying the default syntax highlighting for {distill} and how I created a function that wrapped that process for {distilltools}. I discuss the default syntax highlighting theme used on {distill} sites, and how we can modify it by replacing the five colours used there with five colours of our choosing.\nI also outline the four criteria that were important to me as I went about choosing colours for my own syntax highlighting theme:\nIt be based on the pink that I use in my logo and elsewhere throughout this site\nIt uses colour theory to pick colours that look appealing together\nIt meets WCAG web accessibility guidelines, by ensuring sufficient colour contrast, i.e. a ratio of 4.5:1, between each of the colours in the theme and this site’s background colour (white)\nThe colours in the palette are colourblind-friendly, i.e. still distinguishable to people with various difference types of colourblindness.\nThis post spins out from Part 1 with a brief primer on colour theory and then a deep-dive into the processes, both thought and practical, of choosing colours for my palette that meet the above criteria. I show how I first went about this to derive the palette that’s implemented throughout this site. I also demonstrate a different, entirely R-based, approach to satisfying the criteria, which I decided to try out after learning more about different colour spaces as I was writing up this post. I much preferred the outcome of one approach to the other, but your mileage may vary.\nA brief primer on colour theory\nColour harmonies\n\n\n\nFigure 1: An HSL colour wheel. Screen shot from https://www.canva.com/colors/color-wheel/, annotations adapted from https://dev.to/rneha725/hsl-and-hsla-in-css-31j3.\n\n\n\nColour theory determines which colours ‘look good’ together, based on their relative position on a colour wheel, such as that in Figure 1, somewhat analogously, I think, to how certain musical intervals sound more pleasing/harmonious than others, depending on the ratio of their frequencies. As shown in Figure 2, there are various different types of colour palettes that are in colour harmony, such as complementary (comprised of colours opposite each other on the wheel), analogous (three colours side by side) and triadic (three colours evenly spaced around the wheel). Note that all the colour schemes are derived from the same twelve colours, spaced evenly around a circle.\n\n\n\nFigure 2: Harmonious colour combinations. Figure from https://www.widewalls.ch/magazine/color-theory-basics-elements-color-wheel.\n\n\n\nColour spaces\nRGB, HSB and HSL\nAnother aspect of colour theory relates to colour spaces, and different ways that colours can be defined. The best known, at least in the context of designing for the web, is RGB (Red Green Blue), which defines a colour by how much of each of those three primary colours it contains, in a range of 0-255. It is the hexidecimal representations of these three numbers that combine to make up the hex code for a colour.\nMore intuitive, however, for adjusting colours, is defining them by HSB (Hue, Saturation, Brightness), also known as HSV (Hue, Saturation, Value). HSB is a simple transformation of the RGB space. Similar to HSB is HSL (Hue, Saturation, Lightness), though HSL is considered an improved over HSB in terms of its perceptual qualities.\nIn HSB, the hue represents the colour type and is a number measured between 0 and 360°; it’s where you are on the colour wheel, ignoring how bright or intense the colour is. Saturation describes the intensity or richness of the hue, measured between 0 and 100%. 100% is the richest version of the colour and 0% is a shade of grey. Brightness measures, you guessed it, the brightness of the colour. Again, it ranges from 0 to 100%, with 0% being black and 100% being a very bright colour (here, black is not the opposite of white). Here’s an excellent article on the HSB system, which also explains how it differs from HSL. The differences between HSB and HSL are also illustrated in Figure 3.\n\n\n\nFigure 3: HSL and HSB sliders for the pink used throughout this site. Image is a screenshot from http://colorizer.org.\n\n\n\nIt’s great to play around with an HSL or HSB colour wheel to get a sense of how harmonious colour schemes are built, and how the colours in them relate to each other on the wheel. I really like the canva colour wheel. It’s pretty simple, with only a few schemes, but it’s nicely designed and easy to use, and the page explains the basics of colour theory too. It’s a fun way to start building a palette. I like how you can pull the dots around the wheel and see how the colours relate, and if you click on a colour in the palette, there are HSL sliders too. Plus, as you move colours around, the background of the page changes colour, which is a nice touch!\nHCL\nWhilst websites on colour theory for designers tend to focus on either the HSB or HSL spaces, and it’s HSB or HSL wheels/sliders that tend to be built into design and colour software and apps, both spaces suffer from a lack of perceptual uniformity. The RGB rainbow palette is notorious for this. In general, RBG/HSB/HSL palettes are not a good choice for statistical graphics and data visualisation, where colour conveys meaning. For these purposes, the HCL colour space (Hue, Chroma, Luminance) offers a much better alternative. It is much more suitable for capturing human colour perception.\nThere is an R package for working with the HCL colour space, the intuitively named {colorspace} (Zeileis et al. 2020). It has many excellent vignettes, including one about the HCL space and its perceptual superiority over other colour spaces. The package also provides colour palettes and scales for {ggplot2}. There is also support for HCL palettes in base R. The HCL space is also used on I want hue, a site about colours aimed at data scientists, which allows you to generate and refine palettes of optimally distinct colours.\n\n\n\nFigure 4: My pink on the Luminance-Chroma plane in the HCL space. Image is a screenshot from http://hclwizard.org.\n\n\n\nI haven’t seen the HCL space used elsewhere, at least not in the myriad of sites on colour theory for designers or colour/design apps than I use or have read when preparing my theme and this post. Perceptual uniformity is arguably more important in choosing colour palettes for data visualisation, where the colour conveys information about the data, than in picking a few colours that look good together for a syntax highlighting scheme.\nApproach 1: ColorSlurp and HSB\nBuilding a palette based on my pink, using colour theory\nAs I discuss in Part 1 of this series, I know that I need a palette of five colours to replace the five colours used in the default syntax highlighting scheme that comes with {distill}. The problem with all the colour schemes defined in Figure 2 is that they use a maximum of four colours. But not to worry! We know from colour theory that we can find 12 colours in harmony by taking evenly spaced colours around the HSL or HSB wheel, i.e. colours whose hues are 30° apart, given fixed values for saturation and brightness/lightness. Since we only need five colours, it’s sufficient to find the six colours that are 60° apart, and ignore one of them. Note that for five colours to appear harmonious, we have to respect these angles, not choose five colours that are 72° apart.\nThe main pink that I use in this site has hex #D4006A. I use a great little Mac app called ColorSlurp for building and assessing colour palettes. The basic version is free, though the pro version has great features for testing accessibility - more on that below. In ColorSlurp, I started a new palette with #D4006A as a starting point, then, making sure I was in HSB mode, found its HSB values are 330°, 100%, 83%. Leaving the S and B sliders where they are, the next colour I needed is 60° around the circle, i.e. at 30°, so I moved the H slider to that value and added the resulting orange to the palette. I then repeated that for 90°, 150°, 210° and 270°, giving me two shades of green, a blue and a purple. With a colour selected in ColorSlurp, you can also pull up the colour harmonies tab, , which gives quick access to some of these colours. As I only need five colours, I discarded one of the greens, keeping the one at 150°, which is complementary to the starting pink.\nIf you don’t use ColorSlurp or a similar app, there are many online options for building a palette in this way, for example http://colorizer.org (add a new color to the palette by clicking on the next square down to the right of the sliders). In both ColorSlurp and on colorizer.org, once you have defined a colour by its HSB values, you can read off the hex code, for ease of use in R.\nAt the end of this stage of the process, based purely on my pink and colour theory, my syntax highlighting palette now stood as in Figure 5. In the HSB space, these colours all have a saturation of 100% and a brightness of 83%.\n\n\n\nFigure 5: Colours for syntax highlighting, starting from my main pink, based only on colour theory\n\n\n\nAdapting for web accessibility\nAs noted in Part 1 of this series, one key feature of the default syntax highlighting scheme for {distill} is that it is optimised for accessibility and colour contrast. According to the Web Content Accessibility Guidelines, at the WCAG AA (minimum contrast) level, this requires that that contrast ratio between text and background colours be at least 4.5:1 for text of 14pt+ (which is the default text size for code in {distill}). The more stringent WCAG AAA (enhanced) level requires a ratio of at least 7:1.\nThe pro version of ColorSlurp includes a contrast checker, as in Figure 6, though there are many websites that also offer this. WebAIM (Web with Accessibility in Mind) has a very handy contrast checker which, like ColorSlurp, also includes sliders for adjusting the colours until the desired contrast is reached. Darkening a colour to improve contrast keeps the hue and saturation the same but reduces the brightness or lightness component (ColorSlurp uses HSB, WebAIM uses HSL).\n\n\n\nFigure 6: Contrast checking in ColorSlurp\n\n\n\nThe pink, blue and purple in the palette created above have a contrast ratio of better than 4.5:1 with the pure white background, but the orange and green do not.\nMy first thought was to keep the pink, blue and purple the same, and to just reduce the brightness of the orange and green until the contrast ratio was a bit better than required. In the HSB space, that gives the palette in Figure 7.\n\n\n\nFigure 7: Reducing brightness in just the orange and green to achieve desired contrasts.\n\n\n\nIt’s not bad, but when I applied that palette as a syntax highlighting scheme, to my eye the pink, blue and purple looked a little too bright relative to the orange.\nMy next thought was to reduce the brightness on all the colours to the level of the least bright colour that passes the accessibility check (the green, at 53%). That gives the palette in Figure 8.\n\n\n\nFigure 8: Reducing brightness in all colours to the level of the green.\n\n\n\nThat looks way too dark for my liking. I don’t think it’s vibrant enough, and, although the colours all have good contrast against the white background, they don’t have much contrast with each other.\nSo, I settled on a compromise position. I reduced the brightness of the original pink, blue and purple from 83% to match the brightness of the accessibility-passing orange (71%), leaving only the green at a brightness of 53%, which it needs to pass the contrast check. This gives the palette in Figure 9. To my eye, the green doesn’t appear considerably more dark/less bright than the other four colours. If anything, the greens in Figures 5 and 8, which both have uniform brighness, look a little too bright compared to the other colours. I guess this is a result of the lack of perceptual uniformity of the HSB space.\n\n\n\nFigure 9: The palette I settled on for my syntax highlighting scheme.\n\n\n\nI’m happy with that, and that’s the syntax highlighting scheme I’ve adopted throughout this site, despite the fact that the palette now doesn’t actually include the pink that I set out to build my scheme around! However, because of the process I’ve followed, the pink that is in the palette does tone well with the brighter pink and I think my site still has a consistent look. In the end, it was more important that all the colours in the palette looked consistent together and met accessibility guidelines.\nI am only just beginning to learn about web accessibility, and I know my site does not yet meet all best practices, but I’m committed to improving in this area. I first became aware of the issue of web accessibility because I follow Silvia Canelón on twitter and I highly recommend you do the same! The a11y project and WebAIM are great places to learn more.\nChecking for colourblindness\nSome visual impairments require a high colour contrast between text and background colour in order to be able to read content on the web. Another class of visual impairment worth paying attention to when designing palettes is that of colour blindness.\nNick Tierney has some excellent resources about colour and colourblindness and R packages for accessing these. These comprehensive slides cover what colour is and how we perceive it, colourblindness, how to check how palettes/plots appear to those with different types of colourblindness, the HCL space, the {colorspace} package and how to create your own palettes. He also has a short blog post on quickly assessing colour palettes to ensure they’re colourblind-friendly.\nAs recommended in the above posts, I used the {prismatic} package by Emil Hvitfeldt to check how my syntax highlighting palette appears to those with different types of colourblindness:\n\n\nlibrary(prismatic)\nek_highlight_colours <- c(\"#5B00B6\", \"#005BB6\", \"#008643\", \"#B65B00\", \"#B6005B\")\ncheck_color_blindness(ek_highlight_colours)\n\n\n\n\n\n\nFigure 10: Checking my palette for how it appears to those with various types of colourblindness.\n\n\n\nThankfully, for all three main types of colourblindess, the five colours in the palette are distinguishable, so no further adjustments are necessary.\nApproach 2: An R-based HCL alternative\nThe above sections describe the processes, both thought and practical, that I went through to derive the colour palette for my syntax highlighting scheme, and I’m happy with what I came up with. As I was deriving my scheme, I was working in ColorSlurp and only had a cursory knowledge of the differences between the HSB, HSL and HCL colour spaces.\nHowever, as I was writing up this blog post, I become increasingly curious about alternative approaches I might have taken. In particular, could I have come up with a scheme that met my criteria entirely in R? Given the incredible ecosystem that R is, it should be no surprise that the answer turned out to be yes! So, below is this alternative approach, using the {colorspace}, {coloratio} and {prismatic} packages. Also, whereas the previous approach is based on the HSB colour space, this one uses HCL.\nBuilding a palette based on my pink, using colour theory\nThe {colorspace} package uses the HCL color space, so the first task was to convert a hex code into its hue, chroma and luminance components, and make them available for future use, which can be done as follows:\n\n\nlibrary(colorspace)\npink <- hex2RGB(\"#D4006A\", gamma = FALSE)\npink_hcl <- as(pink, \"polarLUV\")\n\npink_h <- pink_hcl@coords[1, \"H\"]\npink_c <- pink_hcl@coords[1, \"C\"]\npink_l <- pink_hcl@coords[1, \"L\"]\n\n\n\nThe function from {colorspace} that is going to do the hard work of building a palette with differing hues but constant chroma and luminance (or as close as it can in HCL space) is qualitative_hcl(). By default, you give it the number of colours you want, and it works out equally spaced hues, starting at 0°. To override this default, you can give the h argument a start and end value, c(start, end). Again, I’m going to choose six colours, 60° apart, and discard one of them.1 The start value should be in [0, 60) and the end value should be in [300, 360). Let the hue of our starting pink be pink_h. Then all the colours in the palette are going to have a hue pink_h + 60 * k for some integer k. The following code picks the start and end values we need to pass to h:\n\n\nseq_60 <- seq(from = -300, to = 300, by = 60)\npink_60 <- seq_60 + pink_h\n\npink_h_lower <- pink_60[which((pink_60 >= 0 & pink_60 < 60))]\npink_h_upper <- pink_60[which((pink_60 >= 300 & pink_60 < 360))]\n\n\n\nThat’s most of the hard work. Now we build the palette:\n\n\nhcl_six <- qualitative_hcl(\n  6, \n  h = c(pink_h_lower, pink_h_upper), \n  c = pink_c, \n  l = pink_l\n) \n\n\n\n\n\n\n\n\n\nFigure 11: Six colours, with hues approximately 60° apart and roughly equal luminance, based around my pink.\n\n\n\nThe only personal decision I make in this section is which of these six colours to discard. Removing the first of the greens gives me the palette in Figure 12.\n\n\n\nFigure 12: As in the previous figure but minus a green and rearranged\n\n\n\n\n\n\n[UPDATE: May 27th 2021: Since publishing this post, Achim Zeileis, the author of the {colorspace} package, got in touch with me on twitter to offer a bit more insight into what’s going on with this palette. The hcl_six palette does not, as I originally stated, have constant chroma. I have corrected the text above. Not all combinations of Hue/Chroma/Luminance exist in HCL space. At the luminance of my pink (~46) not many other hues can have such high chroma (~118), as demonstrated in Figure 13.\n\n\nhclplot(hcl_six)\n\n\n\n\nFigure 13: Hues and Chromas in HCL space at the Luminance of my pink\n\n\n\nqualitative_hcl() struggles in such circumstances, though does try to keep the luminance of the palette constant.]\nAdapting for web accessibility\nWhen I was developing my scheme, I used my trusted ColorSlurp app to adjust colours to ensure they met WCAG standards of web accessibility. In writing up this post, I since learnt about web resources to do the same (e.g. WebAIM contrast checker) and now, for this section, I’ve discovered the {coloratio} by Matt Dray and {savonliquide} by Mohamed El Fodil Ihaddaden packages that can do this in R.\nBoth packages have much to recommend them. {savonliquide} has the advantage of being on CRAN, and provides a toolbox that allows the user to implement accessibility-related concepts, including, but not limited to, contrast checking. {coloratio} is GitHub only, and only for contrast checking, but it has some additional functionality in that area above {savonliquide}, such as quick plotting of the colours in contrast, and a function, cr_choose_bw() that chooses which of black or white has the better contrast ratio with a user supplied colour (which, incidentally, I use to automatically choose the text colour when highlighting words with different background colours, e.g. #D4006A vs #00D46A).\nBelow, I use the cr_get_ratio function from coloratio to check the colour contrasts of each colour in the palette. Because it’s not vectorised, I use this in conjunction with map2_dbl from {purrr} to get all the contrasts at once.\nIf any of the contrasts are less than 4.5, I then call on the darken() function from {colorspace}, which adjusts each colour in the palette to make it, you guessed it, a bit darker, therefore improving the contrast ratio. I loop over these checking and darkening iterations until all colours in the palette have a contrast ratio of at least 4.5:1 compared to white. Here is the code that achieves this:\n\n\nlibrary(coloratio)\nlibrary(purrr)\n\npalette <- hcl_six[c(6, 1, 3:5)]\ncontrasts <- map2_dbl(palette, \"white\", ~cr_get_ratio(.x, .y, quiet = TRUE))\nmin_contrast <- 4.5\nany_too_light <- any(contrasts < min_contrast)\n\nwhile (any_too_light) {\n  palette <- darken(palette, amount = 0.05)\n  contrasts <- map2_dbl(palette, \"white\", ~cr_get_ratio(.x, .y, quiet = TRUE))\n  any_too_light <- any(contrasts < min_contrast)\n}\n\n\n\nAt the end of the process, the palette looks like this:\n\n\n\nFigure 14: An HCL palette where all colours have a contrast ratio of 4.5:1 or better against white\n\n\n\nChecking for colourblindness\nAs before, we use {prismatic} to check how the palette appears to those with various types of colourblindess. Whilst R can help us visualise this, we still need to use our judgement as to whether the output is acceptable. I believe, in Figure 15, it is.\n\n\n\nFigure 15: Checking how the darkened HCL palette appears to those with various types of colourblindness.\n\n\n\nBut, do I like it?\nGoing through the process of building a colour palette that meets my criteria purely in R, in as automated, reproducible and adaptable way as possible has been a great learning experience for me, and hopefully something that will be useful to others. I don’t much like the palette it produced, though, especially in comparison to the one I came up with previously. Although the HCL-based palette probably has slightly better theoretical perceptual qualities, I prefer the vibrancy of the colours in the palette I came up with using my first approach, and that’s the one I’ve adopted on this site.\nBack to Part 1\nNow that I have chosen my colour palette, head back to Part 1 for details of how to modify the default {distill} syntax highlighting theme to incorporate them, and how to apply the custom theme to a {distill} site.\n\n\n\nZeileis, Achim, Jason C. Fisher, Kurt Hornik, Ross Ihaka, Claire D. McWhite, Paul Murrell, Reto Stauffer, and Claus O. Wilke. 2020. “colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes.” Journal of Statistical Software 96 (1): 1–49. https://doi.org/10.18637/jss.v096.i01.\n\n\nAgain, I want to stress that this 60° apart approach and discard one is NOT something you should do when building a five-colour palette for a data visualisation. There, where the colours mean something in relation to the data, it’s important that the hues are evenly spaced. Even for qualitative data, the perceptual uniformity of five evenly-spaced colours is preferable. However, for a syntax highlighting scheme, where any of the colours can appear next to any of the others, and we want all pairs to look good together, and the colours convey no meaning, based on my current and still somewhat limited knowledge of colour theory, I think the six-at-sixty-degrees-discard-one approach is preferable (though I could probably be persuaded otherwise if anyone has a compelling case for an evenly-spaced 5 colours in this context too).↩︎\n",
    "preview": "posts/2021-05-26-custom-syntax-highlighting-for-distill-part-2-creating-the-palette/ek-syntax-highlighting-palette.png",
    "last_modified": "2021-05-27T11:08:21+01:00",
    "input_file": "custom-syntax-highlighting-for-distill-part-2-creating-the-palette.knit.md",
    "preview_width": 1120,
    "preview_height": 542
  },
  {
    "path": "posts/2021-05-25-custom-syntax-highlighting-for-distill-part-1-modifying-the-default-theme/",
    "title": "Custom Syntax Highlighting for {distill} Part 1: Modifying the default theme",
    "description": "A guide to modifying the default {distill} syntax highlighting theme, including colour choice considerations, and its implementation in {distilltools}",
    "author": [
      {
        "name": "Ella Kaye",
        "url": "https://twitter.com/ellamkaye"
      }
    ],
    "date": "2021-05-25",
    "categories": [
      "distill",
      "distilltools",
      "colour",
      "accessibility"
    ],
    "contents": "\n\nContents\nTL;DR\nBut first, the default\nIn praise of the default\nSo, why change?\nDistill/pandoc documentation\nFinding and saving the default\nCloser inspection of the default\n\nBuilding my own palette\nModifying arrow.theme\nWrapping in a {distilltools} function\nUsing the theme\n\nTL;DR\nThe {distill} package for R can be used to build easy-to-maintain websites written only in R Markdown, such as this one.1\nI wrote a function to modify the default syntax highlighting theme. This modify_default_highlighting function is now part of the {distilltools} package.\nHere’s the function in action, to get the theme used on this site:\n\n\n# get distilltools, requires remotes >= 2.2\nremotes::install_github(\"EllaKaye/distilltools\") \n\nlibrary(distilltools)\nmodify_default_highlighting(\n  name = \"ek_syntax_highlighting\",\n  numeric = \"#B6005B\", # replaces the default red\n  strings = \"#008643\", # replaces the default green\n  functions = \"#005BB6\", # replaces the default purple\n  control = \"#5B00B6\", # replaces the default blue\n  constant = \"#B65B00\" # replaces the default brown\n)\n\n\n\nAnd here’s the theme in action:\n\n\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npenguins %>%\n  mutate(\n    long_flipper = case_when(\n      species == \"Adelie\" & flipper_length_mm > 195 ~ TRUE,\n      species == \"Chinstrap\" & flipper_length_mm > 200 ~ TRUE,\n      species == \"Gentoo\" & flipper_length_mm > 225 ~ TRUE,\n      TRUE ~ FALSE\n    )\n  ) %>%\n  mutate(\n    long_bill = case_when(\n      species == \"Adelie\" & bill_length_mm > 42 ~ TRUE,\n      species == \"Chinstrap\" & bill_length_mm > 52 ~ TRUE,\n      species == \"Gentoo\" & bill_length_mm > 50 ~ TRUE,\n      TRUE ~ FALSE\n    )\n  )\n\n\n\nThis is the first in a series of two posts on implementing a custom syntax highlighting theme for a website or blog built with {distill}. Read on here for why and how this function was built, what it does and doesn’t do, and its inclusion in the {distilltools} package. This post also outlines the criteria that were important to me when choosing colours for my theme, but take a look at Part 2, custom syntax highlighting for {distill}: creating the palette, for a deep dive into considerations about colour choices, in respect to both colour theory and accessibility, and how I ensured my criteria were met.\nBut first, the default\nIn praise of the default\nBefore I delve into how to create a custom syntax highlighting scheme, I want to take a minute to admire the default. The authors of {distill}, in particular Alison Hill, have thought and worked hard to ensure that {distill} provides a good user experience, both for the site’s author AND for those reading it. One of the key considerations for the latter is a default syntax highlighting scheme with colours that are optimised for accessibility and colour contrast. I say more about what that means below and in Part 2. Also, it appears that the colours in the scheme work well together, and overall, on the many {distill} websites where I’ve seen the scheme used, I think it looks really good! For a great example of the default in action, check out this code-chunk-heavy post by Tom Mock.\nSo, why change?\n\n\n\nWhen I used the default syntax highlighting theme on my site I found, to my eye, that the red used for numeric variables clashed with the bright pink (closest colour name “razzmatazz”) I’ve used in my logo and elsewhere throughout the site. So, I decided to tweak the default theme swapping the red for my pink and, to match it, more vibrant versions of the remaining colours.\nDistill/pandoc documentation\nMy first task was to find out whether this was possible, and if, so, how. Thankfully, the {distill} documentation contains a section on syntax highlighting, showing that there is an option to give distill_article a path to a custom .theme file. The linked pandoc documentation on syntax highlighting demonstrates how to use pandoc in the command line to save a personal version of the pygments highlighting theme. The documentation points out that that copy of the pygments .theme file can then be edited to create a custom theme.\nFinding and saving the default\nOnce I had a general strategy of copying and editing an existing .theme file, my next task was to find the .theme file for the default used in {distill}, because that’s what I’d already decided to take as my starting point.\nI cloned the distill repo from GitHub and opened it in RStudio.2 From there I began my detective work with one of my favourite RStudio features, ‘Find in Files’ (⇧ + ⌘ + f on a Mac), which searches across all files in a project. I searched for “highlight” and followed various trails until I discovered that the default is called arrow.theme and is stored in inst/rmarkdown/templates/distill_article/resources/. Thankfully, because it’s in the inst folder, the file is accessible to users who have the {distill} package installed. In the RStudio project for my website, I created a new script, syntax_highlighting.R, in the R folder I have in my root directory, then I ran the following to save a copy of arrow.theme into my website’s root directory:\n\n\narrow_theme_path <- system.file(\n  \"rmarkdown/templates/distill_article/resources/arrow.theme\", \n  package = \"distill\"\n)\n\nfile.copy(arrow_theme_path, \"arrow.theme\")\n\n\n\nWhen I had run that once, I commented out the above lines. I don’t want any future changes in arrow.theme in {distill} to break what I do next.\nCloser inspection of the default\nFrom there I could open up my copy of the arrow.theme file and manually inspect it. I use a great Mac app for building colour palettes, ColorSlurp.3 The basic version is free, though the pro version has useful features for testing accessibility - more on that in Part 2. I set up a new palette in ColorSlurp and, for each hex colour code I encountered, I saved it there.\nThere are 29 types of text-styles in the theme, of which:\n8 are assigned a grey, #5E5E5E, things like Comment and Documentation\n1 is off-black, #111111, Variable\n3 are blue, #007BA5, Other, ControlFlow and Keyword\n4 are green, #20794D, corresponding to various types of string\n1 is purple, #4758AB, Function\n7 are red, #AD0000, a mix of numeric (e.g. BaseN, Float) and things like Alert and Error\n1 is a brown, #8F5902, for Constant\n4 types are not assigned a colour - they are left as null\nI was happy to stick with the groupings, grey, off-black and null in the default, so now I knew I had to pick five colours for my theme.\nBuilding my own palette\nI had four criteria for building a colour palette to use for my syntax highlighting theme:\nIt be based on the pink that I use in my logo and elsewhere throughout this site\nIt uses colour theory to pick colours that look appealing together\nIt meets WCAG web accessibility guidelines, by ensuring sufficient colour contrast, i.e. a ratio of 4.5:1, between each of the colours in the theme and this site’s background colour (white)\nThe colours in the palette are colourblind-friendly, i.e. still distinguishable to people with various difference types of colourblindness.\nI was originally going to write up how I went about building such a palette, both in terms of the thought process and tools used, as part of this post, but it was getting a little long4, so I’ve spun it out into a separate post,custom syntax highlighting for {distill} part 2: creating the palette.\nAt the end of the process, the palette for my syntax highlighting scheme is as in Figure 1.\n\n\n\nFigure 1: The color palette used for syntax highlighting throughout this site.\n\n\n\nModifying arrow.theme\nWith all the pieces in place, it’s now just a case of swapping out the default colour codes for our own choices. Although it’s possible to manually edit the arrow.theme file we now have in our directory, to aid reproducibility, and with a view to writing this up as a function, I edited it using R code instead. I read in the file, substituted the hex codes, then saved the resulting theme into a new ek_syntax_highlighting.theme file (leaving arrow.theme unchanged). Below are two approaches, one using base R, the other in the tidyverse, that I put in my syntax_highlighting.R script.\n\n\n# read in the default theme\ntheme <- readLines(\"arrow.theme\")\n\n# base R approach\ntheme <- gsub(\"#AD0000\", \"#B6005B\", theme) # red -> pink\ntheme <- gsub(\"#8f5902\", \"#B65B00\", theme) # brown -> brown \ntheme <- gsub(\"#007BA5\", \"#5B00B6\", theme) # blue -> purple\ntheme <- gsub(\"#20794D\", \"#B65B00\", theme) # green -> green\ntheme <- gsub(\"#4758AB\", \"#005BB6\", theme) # purple -> blue\n\n# alternatively, tidyverse approach\nlibrary(stringr)\nlibrary(magrittr)\n\ntheme <- readLines(\"arrow.theme\") %>%\n   str_replace_all(\"#AD0000\", \"#B6005B\") %>% # red -> pink\n   str_replace_all(\"#8f5902\", \"#B65B00\") %>% # brown -> brown \n   str_replace_all(\"#007BA5\", \"#5B00B6\") %>% # blue -> purple\n   str_replace_all(\"#20794D\", \"#008643\") %>% # green -> green\n   str_replace_all(\"#4758AB\", \"#005BB6\")     # purple -> blue\n\n# save new theme\nwriteLines(theme, \"ek_syntax_highlighting.theme\")\n\n\n\nI now have the file ek_syntax_highlighting.theme in my root directory, with my colour choices.\nIt is, of course, possible to modify it further, either manually or by making further substutions in the code above. There is a quirk, though: if I swap one of the default hex codes for my own colour choice, that implements just fine, but if I swap any of the nulls for a colour, that doesn’t show up when I apply the theme.\nWrapping in a {distilltools} function\nWhen I figure out code to do something that I think I might want to do again, or think others might find useful, I generally like to write it up as a function, and that’s what I’ve done with the above, wrapping it in a function called modify_default_highlighting and putting it in the {distilltools} package. {distilltools} is in the very early stages of development, an (expanding) collection of tools to support the creation and styling of content on websites created using {distill}.\nWhen I first announced the package, I included in the ‘future functionality’ section of the package README the intention to add a create_highlight_theme function. I don’t think what I’ve done is quite versatile or fully-featured enough to warrant that name. Instead, I called it modify_default_highlighting because that’s all it does, allowing you to swap out the five colours in the default scheme for five colours of your choosing. It does, however, create a .theme file in your working directory, that can be further edited manually, or with your own R code, if further modifications are desired.\nThe first argument to modify_default_highlighting is name, the name you want to give your theme (which will create the file name.theme). It then takes five colour arguments, which can be specified either in the hex form “#RRGGBB” or as a named colour, from the colour names in grDevices::colors(). For a list of the colour names available in R, see page 3 of the R color cheatsheet for a one page summary, or Colors in R for a slightly less visually overwhelming list. The final argument, overwrite (defaults to TRUE) specifies whether to overwrite name.theme if it already exists in the working directory. Here’s the function in action again, this time using colour names (note that I have not tested the visual properties of this as a palette, just dropped in some colour names into the function):\n\n\nlibrary(distilltools)\nmodify_default_highlighting(\n  name = \"ek_syntax_highlighting\",\n  numeric = \"deeppink\", # replaces the default red\n  strings = \"forestgreen\", # replaces the default green\n  functions = \"darkorchid3\", # replaces the default purple\n  control = \"royalbkue3\", # replaces the default blue\n  constant = \"darkorange1\" # replaces the default brown\n)\n\n\n\nUsing the theme\nOnce you have you custom .theme file, you’ll want to apply it to your site. According to the {distill} documentation, you can apply a syntax highlighting theme with the following YAML:\n---\noutput:\n  distill::distill_article:\n    highlight: my_highlighting.theme\n---  \nHere, the available options for highlight include default, rstudio (the default RStudio editor theme), and the haddock, kate, monochrome, pygments and tango pandoc highlighting themes. Also, most importantly for us, it can also take the path to a .theme file.\nPresumably, we should be able to add this to our _site.yml file to have the theme apply site-wide (though note you’ll have to rebuild the site and re-knit any posts where you want to it apply). However, that’s not working for me. I have raised an issue about it. If you face the same problem, it would be helpful if you could comment there too.\nThere is a workaround, though, which is that the above YAML can also be included in individual .Rmd articles, in which case the theme applies just fine, though note that if your .theme file is in you root directory, you’ll need to give the full path to it.5 And if it sounds like a bit of a pain to have to add that every time you write a new post, consider creating a template for your posts, including those lines, and then starting new posts with the {distilltools} function create_post_from_template().6\n\nFor more on resources and inspirations for setting up a {distill} website, see my previous post, Welcome to my {distill} website.↩︎\nFrom RStudio, go to ‘File’ in the menu bar, then ‘New Project…’ Chose ‘Version Control’, then ‘Git’, then enter https://github.com/rstudio/distill.git as the ‘Repository URL:’ and click ‘Create Project’↩︎\nI don’t have experience of colour apps on other operating systems, but a quick search for ColorSlurp alternatives suggest there are a bunch to pick from.↩︎\nAs part of the process of writing the post, I learnt much more about colour theory, and alternatives to the approach that I had originally taken, and I wanted to share it all!↩︎\nIf you happen to inspect the source code for this post, you might notice that I have copied ek_syntax_highlighting.theme into the directory. This is not necessary for my site (using the full path to the .theme folder in my root directory is sufficient). However, I needed to do this to get the theme to show in the version of this post in the distillery.↩︎\nNote that the create_post_from_template() function is likely to get wrapped into {distill} itself, or its functionality included in distill::create_post(), and will be depreciated from {distilltools} if so. (I have had some discussion with the {distill} team about this and will be submitting a PR in the near future.)↩︎\n",
    "preview": "posts/2021-05-25-custom-syntax-highlighting-for-distill-part-1-modifying-the-default-theme/more-theme-in-action.png",
    "last_modified": "2021-05-26T16:12:25+01:00",
    "input_file": {},
    "preview_width": 1850,
    "preview_height": 1470
  },
  {
    "path": "posts/2021-05-08-welcome-to-my-distill-website/",
    "title": "Welcome to my {distill} website!",
    "description": "Resources and sites I found inspiring when building my new site, and a sneak-peek at {distilltools}, an exciting new project for {distill} users",
    "author": [
      {
        "name": "Ella Kaye",
        "url": "https://twitter.com/ellamkaye"
      }
    ],
    "date": "2021-05-08",
    "categories": [
      "distill",
      "distilltools",
      "R package development"
    ],
    "contents": "\n\nContents\nWhy {distill}?\nResources\nThe basics\nNext steps\n\nInspirations/Code\nFinding out more\nThe distillery\nTwitter\n\nA sneak-peek at {distilltools}\n\nHello, and welcome to my new site, built using the {distill} package. Here’s why I switched from {blogdown}, and the resources and inspirations that helped me in the process.\nWhy {distill}?\nAs the documentation says, {distill} for R Markdown is a web publishing format optimised for scientific and technical communication. Recent updates to the package, particularly the ability to customise the theme through the create_theme() function, have made it a really appealing choice for those wanting a personalised website based only on R Markdown. The fact that {distill} is made just in R Markdown is a big win for those not wanting to go down (or, like me, looking to get away from), the Hugo route. I’d had a Hugo Academic website for four years, built on {blogdown}, and had been stung a number of times by it breaking after updates to Hugo and Hugo Academic. Last year, I switched to {hugodown}, and that helped, but I had some serious FOMO following that shift after the release of {blogdown} v1.0 a few months later, with all its handy check functions. By then, anyway, I was also displeased with the shift from Hugo Academic to Wowchemy, and getting a little bored of that theme anyway. I had also started seeing more and more {distill} sites pop up from those I admire in the RStats community. I looked into it and and I loved the simplicity of it, both in looks and in management. No more impenetrable file structures! No more not being sure quite why my website is working/looking as it does! Attending Alison Hill’s incredible ‘Crafting Kind Tools’ talk, in which she described the care put into making the {distill} user experience an enjoyable one, was the last push I needed to start my website again (though, to be fair, that talk also described similar care put into the latest release of {blogdown}).\nI’m finding working with {distill} to be an absolute joy!\nResources\nThis post is not a guide on how to get a {distill} site up an running. There are already great resources for that. In particular, here are the resources I found helpful.\nThe basics\nThe blogpost from RStudio on (Re-)introducting Distill for R Markdown is a great place to start.\nFor getting up and running, the official {distill} documentation is excellent (and also a {distill} website).\nWhilst we’re on resources from the RStudio team, it’s worth remembering that because {distill} is built on {rmarkdown}, recent developments to that package, such as the ability to style a site with {sass} 1, and developments in {knitr}, such as the ability to easily add alt-text to images, follow through to {distill} too.\nThere’s a great building a blog with distill post from Tom Mock\nAnd one on building a {distill} website from Lisa Lendway\nNext steps\nThe {postcards} package from Sean Kross makes it incredibly easy to create simple, stylish, landing pages, and they make great home pages for {distill} sites. Alison Hill has a walk-through on how to set this up: M-F-E-O: postcards + distill\nTom Mock has another excellent {distill} post on including and meta tagging extra content in a distill blog, useful for if/when you want your site to contain content other than distill_articles\nWhilst the create_post() function in {distill} is a great way to get started on a blog post, Eric Ekholm shows how he developed a function wrapped around it to personalise the {distill} template\nFor styling content, John Helveston shows how to customise {distill} with {htmltools} and CSS.\nIf you want to allow readers to comment on your posts, then follow this guide from Vebash Naidoo on how to enable utterances with {distill}\nInspirations/Code\nI’m extremely grateful to the authors of the above posts for taking the time to write up what they’ve developed and what they know/have learnt to do, therefore making it easy for others to apply. I guess that’s what blogs are for! But I’ve also learnt a lot from finding sites that I simply like the look of, or have cool features, and looking at the source code on GitHub and adapting it for my own site. Here are some sites that I’ve drawn on for inspiration and code:\n\n\n\nJohn Helveston\n\n site source\n\nI particularly like his icon_link buttons (as demonstrated just above), and the second collection for talks. John tells me he is turn took inspiration for this from Emi Tanaka’s site.\nIjeamaka Anyene\n\n site source\n\nIjeamaka has a really cool projects page, where she’s created a card for each project, which I’ve implemented on my site.\nTom Mock\n\n site source\n\nCome for the minimalist, stylish design, stay for the fantastic blog content, not just on {distill}, but also on {gt}, R Markdown, #TidyTuesday and much more besides.\nFinding out more\nThe above just scratches the surface. There are many more great sites built on {distill} out there, and lots more ways to customise them. Below are some good ways to find out more.\nThe distillery\nThe distillery is a {distill} blog about building {distill} blogs and websites. As the site’s GitHub README states:\n\nThis site was built for the community of distill users to find ways to build and customize their sites and to inspire one another. If you have a distill website or blog, we would love to have it included in the distillery showcasehttps://distillery.rbind.io/showcase.html! Have a post about ways to customize or add new features to your blog? We would love to have it included on the distillery tips & tricks page!\n\nThe showcase is a great place to browse sites for inspiration and the tips and tricks page has loads of great resources (many of which I want to implement on my site in the future, for example Jannick Buhr’s post on making a dark mode for your {distill} site).\nTwitter\nThere are a number of folk who tweet about {distill} (alongside other #rstats content). I’ve seen useful tweets from Shannon Pileggi @PipingHotData, Lisa Lendway @lisalendway and John Helveston @JohnHelveston. And it pretty much goes without saying that anyone with an interest in {distill} should be following its authors (and general R Markdown gurus), Alison Hill @apreshill, Christophe Dervieux @chrisderv, Rich Iannone @riannone and Yihui Xie @xieyihui (note that the author and original creator of {distill} is JJ Allaire - he does have a twitter account but doesn’t seem to use it).\nA sneak-peek at {distilltools}\nInspiried by the above-mentioned posts from John Helveston and Eric Ekholm, I’ve started working on a package, {distilltools}, a collection of tools to support the creation and styling of content on websites created using {distill}.\n\n site source\n\nIt is in the very early stages of development. I am actively seeking contributions - both ideas and code - to help build the package to be broadly useful to a wide variety of {distill} users. The idea is for the package to become a curated, collaborative, community-driven project. Please see the contributing guide for more details on how to get involved. In terms of relationship between packages, I hope in time that {distilltools} can be for {distill} something like what {xaringanExtra} and {xaringanthemer} are for {xaringan}. Some of what I have in mind may sit better within the distill package itself, and I am in touch with the {distill} team about that.\nAt the time of writing, there are just three functions:\nicon_link: creates the html for a link button with icon and text (as seen above). Output of icon_link will need styling via the icon-link class to make it look like a button.\ncreate_talk(): a wrapper around distill::create_post() that creates a post in the talk directory and includes buttons (made with icon-link()) for slides (both web and pdf), material, video and project. These can easily be edited in the resulting .Rmd file.\ncreate_post_from_template(): this function operates almost identically to distill::create_post() except for the addition of a path argument, which allows the user to pass in a path to an .Rmd file that can be used as a template for the post. (Note that this function is likely going to be pulled into the {distill} package and hence be depreciated here.)\nExpect to hear much more from me, both on this blog and twitter, about {distilltools} in the near future.\n\nWhen I first tried this in {distill}, I couldn’t get it working, but it seems this has been patched now↩︎\n",
    "preview": "posts/2021-05-08-welcome-to-my-distill-website/distill-logo.png",
    "last_modified": "2021-06-27T17:11:38+01:00",
    "input_file": "welcome-to-my-distill-website.knit.md",
    "preview_width": 735,
    "preview_height": 852
  },
  {
    "path": "posts/2020-12-09-advent-of-code-2020/",
    "title": "Advent of Code 2020",
    "description": "My attempts at Advent of Code, 2020",
    "author": [
      {
        "name": "Ella Kaye",
        "url": "https://twitter.com/ellamkaye"
      }
    ],
    "date": "2020-12-09",
    "categories": [
      "R",
      "Advent of Code"
    ],
    "contents": "\n\nContents\nDay 1: Report Repair\nDay 2: Password Philosophy\nDay 3: Toboggan Trajectory\nDay 4: Passport Processing\nDay 5: Binary Boarding\nDay 6: Custom Customs\nDay 7: Handy Haverstocks\nDay 8: Handheld Halting\nDay 9: Encoding Error\nDay 10: Adapter Array\nDay 11: Seating System\nNext\n\nAdvent of Code is a series of small programming challenges, released daily throughout December in the run-up to Christmas. Part 1 of the challenge is given first. On its successful completion, Part 2 is revealed. The challenges are designed to be solved in any programming language. I will be using R.\nThere will no doubt be a wide variety of ways to solve these problems. I’m going to go with the first thing I think of that gets the right answer. In most cases, I expect that there will be more concise and efficient solutions. Most of the time I’m working in R, it’s within the tidyverse, so I imagine that framework will feature heavily below.\nEach participant gets different input data, so my numerical solutions may be different from others. If you’re not signed up for Advent of Code yourself, but want to follow along with my data, you can download it at from the data links at the beginning of each day’s section. The links in the day section headers take you to challenge on the Advent of Code page.\nDay 1: Report Repair\n\n\n\nMy day 1 data\nPart 1: Two numbers\nThe challenge is to find two numbers from a list that sum to 2020, then to report their product.\nexpand.grid() creates a data frame from all combinations of the supplied vectors. Since the vectors are the same, each pair is duplicated. In this case the two numbers in the list that sum to 2020 are 704 and 1316, and we have one row with 704 as Var1 and one with 704 as Var2. slice(1) takes the first occurrence of the pair.\n\n\nlibrary(dplyr)\n\nexpenses <- readLines(\"data/AoC_day1.txt\") %>%\n  as.numeric()\n\nexpand.grid(expenses, expenses) %>% \n  mutate(sum = Var1 + Var2) %>%\n  filter(sum == 2020) %>%\n  mutate(prod = Var1 * Var2) %>%\n  slice(1) %>%\n  pull(prod)\n\n\n[1] 926464\n\nPart 2: Three numbers\nThe follow-up challenge is the same but with three numbers. I went with essentially the same code but it’s notably slower. There are a lot of repeated calculations here: each triplet appears six times in the table.\n\n\nexpand.grid(expenses, expenses, expenses) %>% \n  mutate(sum = Var1 + Var2 + Var3) %>%\n  filter(sum == 2020) %>%\n  mutate(prod = Var1 * Var2 * Var3) %>%\n  slice(1) %>%\n  pull(prod)\n\n\n[1] 65656536\n\nDay 2: Password Philosophy\nMy day 2 data\nPart 1: Number of letters\nWe need to find how many passwords are valid according to their policy. The policies and passwords are given as follows:\n1-3 a: abcde\n1-3 b: cdefg\n2-9 c: ccccccccc\nEach line gives the password policy and then the password. The password policy indicates the lowest and highest number of times a given letter must appear for the password to be valid. For example, 1-3 a means that the password must contain a at least 1 time and at most 3 times.\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\n\n\n\nFirst load the libraries we’ll need. We then read in the data and use tidyr functions to separate out the parts of the policy and the password, making sure to convert the columns to numeric as appropriate:\n\n\npasswords <- readr::read_tsv(\"data/AoC_day2.txt\", col_names = FALSE) %>%\n  separate(X1, c(\"policy\", \"password\"), sep = \":\") %>%\n  separate(policy, c(\"count\", \"letter\"), sep = \" \") %>%\n  separate(count, c(\"min\", \"max\")) %>%\n  mutate(min = as.integer(min),\n         max = as.integer(max))\n\n\n\nNext, we use the stringr function str_count() to count how many times the given letter appears in the password, and conditional logic to check whether it is repeated within the specified number of times. Because TRUE has a numeric value of 1 and FALSE has a numeric value of 0, we can sum the resulting column to get a count of how many passwords are valid according to their policies.\n\n\npasswords %>%\n  mutate(count = str_count(password, letter)) %>%\n  mutate(password_in_policy = if_else(count >= min & count <= max, TRUE, FALSE)) %>%\n  summarise(correct = sum(password_in_policy)) %>%\n  pull(correct)\n\n\n[1] 625\n\nPart 2: Position of letters\nNow the policy is interpreted differently. Each policy actually describes two positions in the password, where 1 means the first character, 2 means the second character, and so on. Exactly one of these positions must contain the given letter. How many are valid now?\nThere were a couple of gotchas here. When I used separate() in the previous part, I had inadvertently left a leading whitespace in front of the password, something that was messing up my indexing with str_sub. Using str_trim() first cleared that up. Also, we need exactly one of the positions to match. | is an inclusive or. We need xor() for exclusive or instead.\n\n\npasswords %>%\n  mutate(password = str_trim(password)) %>%\n  mutate(pos1_letter = str_sub(password, min, min),\n         pos2_letter = str_sub(password, max, max)) %>%\n  mutate(match_one = xor(pos1_letter == letter, pos2_letter == letter)) %>%\n  summarise(correct = sum(match_one)) %>%\n  pull(correct) \n\n\n[1] 391\n\nDay 3: Toboggan Trajectory\nMy day 3 data\nPart 1: Encountering trees\nStarting at the top left corner of the map, how many trees (“#”) do we encounter, going at a trajectory of 3 right and 1 down?\nFirst, read in the data and save it into a matrix. My method here feels really hack-y. I’m sure there must be a better approach.\n\n\nlibrary(dplyr)\n\ntree_map <- readr::read_tsv(\"data/AoC_day3.txt\", col_names = FALSE)\n\nnum_col <- tree_map %>%\n  mutate(length = str_length(X1)) %>%\n  slice(1) %>%\n  pull(length)\n\ntree_vec <- tree_map %>%\n  mutate(X1 = strsplit(X1, split = character(0), fixed = TRUE)) %>%\n  pull(X1) %>%\n  unlist()\n\ntree_mat <- matrix(tree_vec, ncol = num_col, byrow = TRUE)\n\n\n\nNow work my way across and down the matrix, using the %% modulo operator to loop round where necessary. The -1 and +1 in the line ((y + right - 1) %% num_col) + 1 is a hack to get round the fact that, for num_col columns, the modulo runs from 0 to num_col - 1, but the column indexes for our matrix run from 1 to num_col.\n\n\nright <- 3\ndown <- 1\n\nnum_rows <- nrow(tree_mat)\nnum_col <- ncol(tree_mat)\n\n# start counting trees encountered\ntrees <- 0\n\n# start square\nx <- 1\ny <- 1\n  \nwhile (x <= num_rows) {\n  \n  # cat(\"row: \", x, \"col: \", y, \"\\n\")\n  \n  if (tree_mat[x,y] == \"#\") trees <- trees + 1\n  \n  x <- x + down\n  y <- ((y + right - 1) %% num_col) + 1\n  \n}\n\ntrees\n\n\n[1] 299\n\nPart 2: Checking further slopes\nWe now need to check several other trajectories, and multiply together the number of trees we find, so we wrap the Part 1 code into a function.\n\n\nslope_check <- function(tree_mat, right, down) {\n  \n  num_rows <- nrow(tree_mat)\n  num_col <- ncol(tree_mat)\n\n  # start counting trees encountered\n  trees <- 0\n\n  # start square\n  x <- 1\n  y <- 1\n  \n  while (x <= num_rows) {\n  \n    if (tree_mat[x,y] == \"#\") trees <- trees + 1\n  \n    x <- x + down\n    y <- ((y + right - 1) %% num_col) + 1\n  \n  }\n  trees\n}\n\nprod(slope_check(tree_mat, 1, 1),\n     slope_check(tree_mat, 3, 1),\n     slope_check(tree_mat, 5, 1),\n     slope_check(tree_mat, 7, 1),\n     slope_check(tree_mat, 1, 2))\n\n\n[1] 3621285278\n\nDay 4: Passport Processing\n\n\n\nMy day 4 data\nPart 1: Complete passports\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\n\n\nUsing readr::read_tsv() off the bat removes the blank lines, making it impossible to identify the different passports, but reading in the data via readLines() then converting as_tibble() preserves them, and then allows us to use tidyverse functions for the remaining tidying. cumsum() on a logical vectors takes advantage of FALSE having a numeric value of zero and TRUE having a numeric value of one.\n\n\npassports <- readLines(\"data/AoC_day4.txt\") %>%\n  as_tibble() %>%\n  separate_rows(value, sep = \" \") %>%\n  mutate(new_passport = value == \"\") %>%\n  mutate(ID = cumsum(new_passport) + 1) %>%\n  filter(!new_passport) %>%\n  select(-new_passport) %>%\n  separate(value, c(\"key\", \"value\"), sep = \":\") %>%\n  relocate(ID)\n\n\n\nOur data is now in three columns, with ID, key and value, so now we need to find the number of passports with all seven fields once cid is excluded:\n\n\npassports %>%\n  filter(key != \"cid\") %>%\n  count(ID) %>%\n  filter(n == 7) %>%\n  nrow()\n\n\n[1] 210\n\nPart 2: Valid passports\nNow we need to add data validation checks:\nbyr (Birth Year) - four digits; at least 1920 and at most 2002.\niyr (Issue Year) - four digits; at least 2010 and at most 2020.\neyr (Expiration Year) - four digits; at least 2020 and at most 2030.\nhgt (Height) - a number followed by either cm or in:\nIf cm, the number must be at least 150 and at most 193.\nIf in, the number must be at least 59 and at most 76.\n\nhcl (Hair Color) - a # followed by exactly six characters 0-9 or a-f.\necl (Eye Color) - exactly one of: amb blu brn gry grn hzl oth.\npid (Passport ID) - a nine-digit number, including leading zeroes.\ncid (Country ID) - ignored, missing or not.\nIgnoring the cid field, we narrow down on passports that at least have the right number of fields, and extract the number from the hgt column:\n\n\ncomplete_passports <- passports %>%\n  filter(key != \"cid\") %>%\n  add_count(ID) %>%\n  filter(n == 7) %>%\n  select(-n) %>%\n  mutate(hgt_value = case_when(\n    key == \"hgt\" ~ readr::parse_number(value),\n    TRUE ~ NA_real_)) %>%\n  ungroup()\n\n\n\nThen we create a check column, which is TRUE when the value for each key meets the required conditions. Those with 7 TRUEs are valid. Note that with case_when() we’ve left the check column as NA when the condition is FALSE, requiring na.rm = TRUE in the call to sum(). We can get round that by adding a final line to the case_when() condition stating TRUE ~ FALSE. TRUE here is a catch-all for all remaining rows not covered by the conditions above, and then we set them to FALSE, but I find the line TRUE ~ FALSE unintuitive.\n\n\ncomplete_passports %>%\n  mutate(check = case_when(\n    (key == \"byr\" & value >= 1920) & (key == \"byr\" & value <= 2002) ~ TRUE,\n    (key == \"iyr\" & value >= 2010) & (key == \"iyr\" & value <= 2020) ~ TRUE,\n    (key == \"eyr\" & value >= 2020) & (key == \"eyr\" & value <= 2030) ~ TRUE,\n    key == \"hgt\" & str_detect(value, \"cm\") & hgt_value >= 150 & hgt_value <= 193 ~ TRUE,\n    key == \"hgt\" & str_detect(value, \"in\") & hgt_value >= 59 & hgt_value <= 76 ~ TRUE,  \n    key == \"hcl\" & str_detect(value, \"^#[a-f0-9]{6}$\") ~ TRUE,\n    key == \"ecl\" & value %in% c(\"amb\", \"blu\", \"brn\", \"gry\", \"grn\", \"hzl\", \"oth\") ~ TRUE,\n    key == \"pid\" & str_detect(value, \"^[0-9]{9}$\") ~ TRUE\n  )) %>%\n  group_by(ID) %>%\n  summarise(check_all = sum(check, na.rm = TRUE)) %>%\n  filter(check_all == 7) %>%\n  nrow()\n\n\n[1] 131\n\nDay 5: Binary Boarding\nMy day 5 data\nPart 1: Finding all seat IDs\n\n\nlibrary(dplyr)\nlibrary(stringr)\n\n\n\nThe code below sets starts by setting each row number to 127 and each column number to 7, the maximum they can be, then, working along the string, lowering the maximum (or leaving it as is) one letter at a time:\n\n\nboarding <- readr::read_tsv(\"data/AoC_day5.txt\", col_names = FALSE) %>%\n  rename(binary = X1)\n\nseat_IDs <- boarding %>%\n  mutate(row = 127) %>%\n  mutate(col = 7) %>%\n  mutate(row = if_else(str_sub(binary, 1, 1) == \"F\", row - 64, row)) %>%\n  mutate(row = if_else(str_sub(binary, 2, 2) == \"F\", row - 32, row)) %>%\n  mutate(row = if_else(str_sub(binary, 3, 3) == \"F\", row - 16, row)) %>%\n  mutate(row = if_else(str_sub(binary, 4, 4) == \"F\", row - 8, row)) %>%\n  mutate(row = if_else(str_sub(binary, 5, 5) == \"F\", row - 4, row)) %>%\n  mutate(row = if_else(str_sub(binary, 6, 6) == \"F\", row - 2, row)) %>%\n  mutate(row = if_else(str_sub(binary, 7, 7) == \"F\", row - 1, row)) %>%\n  mutate(col = if_else(str_sub(binary, 8, 8) == \"L\", col - 4, col)) %>%\n  mutate(col = if_else(str_sub(binary, 9, 9) == \"L\", col - 2, col)) %>%  \n  mutate(col = if_else(str_sub(binary, 10, 10) == \"L\", col - 1, col)) %>%  \n  mutate(ID = row * 8 + col) \n\nseat_IDs %>%\n  summarise(max = max(ID)) %>%\n  pull(max)\n\n\n[1] 963\n\nOK, I know I said in the introduction to this post that I would go with the first solution I think of that gets the right answer, and the above does work, but I’m deeply unhappy with the code. There’s too much repetition, I don’t like the use of subtraction when diving by 2 feels more appropriate in a binary context, and it doesn’t feel like I’ve taken full advantage of the mathematical structure of the problem. So, on further reflection, I realise that the way that ID is defined is essentially turning a binary number into a decimal, where we get the binary number as a string by replacing “B” and “R” by “1” and L\" and “F” by “0”. Then, I just found, there is a base R function strtoi() that takes a string of digits in a given base and converts it to a base 10 integer, just what we need:\n\n\nseat_IDs <- boarding %>%\n  mutate(binary = str_replace_all(binary, \"L|F\", \"0\")) %>%\n  mutate(binary = str_replace_all(binary, \"B|R\", \"1\")) %>%\n  mutate(ID = strtoi(binary, base = 2)) %>%\n  arrange(desc(ID))\n\nseat_IDs %>%\n  slice(1) %>%\n  pull(ID)\n\n\n[1] 963\n\nThat’s better!\nPart 2: Finding my seat ID\nWe need to find the missing number, so we arrange the IDs in ascending order and look at the gap between each ID and the preceding one. In most cases, that should be one. Where we have a gap of 2, we must have skipped the integer below:\n\n\nseat_IDs %>%\n  arrange(ID) %>%\n  mutate(diff = lag(ID)) %>%\n  mutate(gap = ID - diff) %>% \n  filter(gap == 2) %>%\n  summarise(my_seat = ID - 1) %>%\n  pull(my_seat)\n\n\n[1] 592\n\nDay 6: Custom Customs\nMy day 6 data\nPart 1: Anyone answers\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\n\n\n\nWithin each group, we need to find the number of unique letters within each group. We read in and separate the data using the tricks learnt for Day 4, and take advantage of the rowwise() feature in dplyr 1.0.0.\n\n\ncustoms_groups <- readLines(\"data/AoC_day6.txt\") %>%\n  as_tibble() %>%\n  mutate(new_group = value == \"\") %>%\n  mutate(group_ID = cumsum(new_group) + 1) %>%\n  filter(!new_group) %>%\n  select(-new_group) %>%\n  group_by(group_ID) \n\ncustoms_groups %>%\n  summarise(qs = str_c(value, collapse = \"\")) %>%\n  ungroup() %>%\n  mutate(qss = str_split(qs, \"\")) %>%\n  rowwise() %>%\n  mutate(qsu = list(unique(qss))) %>%\n  mutate(count = length(qsu)) %>%\n  ungroup() %>%\n  summarise(total = sum(count)) %>%\n  pull(total)\n\n\n[1] 6585\n\nPart 2: Everyone answers\nNow, instead of unique letters in a group, we need to find the number of letters which appear in all the answers for everyone in the same group. I first note how many people are in each group, then tabulate the number of occurrences of each letter in the group, then count (by summing a logical vector) the number of matches between occurrences of letter and the number in group. Finally, we sum across all groups.\n\n\ncustoms_groups %>%  \n  add_count(group_ID, name = \"num_in_group\") %>%\n  group_by(group_ID, num_in_group) %>%\n  summarise(qs = str_c(value, collapse = \"\")) %>%\n  ungroup() %>%\n  mutate(qss = str_split(qs, \"\")) %>%\n  rowwise() %>%\n  mutate(letter_table = list(table(qss))) %>%\n  slice(1) %>%\n  mutate(in_common = sum(num_in_group == letter_table)) %>%\n  ungroup() %>%\n  summarise(total = sum(in_common)) %>%\n  pull(total)\n\n\n[1] 3276\n\nDay 7: Handy Haverstocks\nMy day 7 data\nPart 1: Number of colour bags\n\n\nlibrary(tidyverse)\n\n\n\nWe have colour-coded bags that must contain a specific number of other colour-coded bags.\n\n\nbags <- read_tsv(\"data/AoC_day7.txt\", col_names = FALSE)\n\nhead(bags)\n\n\n# A tibble: 6 x 1\n  X1                                                                  \n  <chr>                                                               \n1 wavy bronze bags contain 5 striped gold bags, 5 light tomato bags.  \n2 drab indigo bags contain 4 pale bronze bags, 2 mirrored lavender ba…\n3 pale olive bags contain 3 faded bronze bags, 5 wavy orange bags, 3 …\n4 faded white bags contain 5 vibrant violet bags, 4 light teal bags.  \n5 mirrored magenta bags contain 2 muted cyan bags, 3 vibrant crimson …\n6 dull purple bags contain 1 striped fuchsia bag.                     \n\nOur first task is to parse the natural language and split the rules into one container/contains pair per line:\n\n\nrules <- bags %>%\n  mutate(rule = row_number()) %>%\n  separate(X1, c(\"container\", \"contains\"), sep = \" bags contain \") %>%\n  separate_rows(contains, sep = \",\") %>%\n  mutate(contains = str_remove(contains, \"\\\\.\")) %>%\n  mutate(contains = str_remove(contains, \"bags|bag\")) %>%\n  #mutate(contains = str_replace(contains, \"no other\", \"0 other\")) %>%\n  extract(contains, c('number', 'contains'), \"(\\\\d+) (.+)\") %>%\n  filter(!is.na(number)) %>%\n  mutate(contains = str_trim(contains)) %>%\n  mutate(number = as.integer(number)) \n\n\n\nTo find all bags that con eventually contain our shiny gold bag, we first find the bags that can contain it directly. We then find the bags that can contain those bags and take the union of the two levels. We repeat, stopping when going up a level adds no further bags to the vector of bag colours already found. We then subtract 1, because we don’t want to count the original shiny gold bag.\n\n\n# function to find all colours that contain a vector of other colours:\ncontains_colours <- function(colours) {\n  rules %>%\n    filter(contains %in% colours) %>%\n    distinct(container) %>%\n    pull(container)\n}\n\nbags <- \"shiny gold\"\nold_length <- length(bags)\nnew_length <- 0\n\n# keeping adding to the vector of bags, until no change\nwhile(old_length != new_length) {\n  old_length = length(bags)\n  bags <- base::union(bags, contains_colours(bags)) %>% unique()\n  new_length <- length(bags)\n  #cat(old_length, \", \", new_length, \"\\n\")\n}\n\nlength(bags) - 1\n\n\n[1] 274\n\nPart 2: Number of bags\nNow we need to discover the number of bags that a shiny gold bag must contain. I figured that lends itself to recursion, but struggled on the details. Hat tip to David Robinson for this solution. I’ve learnt a lot for myself by unpicking how it works.\n\n\ncount_all_contained <- function(colour) {\n  \n  relevant_rules <- rules %>%\n    filter(container %in% colour)\n  \n  sum(relevant_rules$number * (1 + map_dbl(relevant_rules$contains, count_all_contained)))\n  \n}\n\ncount_all_contained(\"shiny gold\")\n\n\n[1] 158730\n\nDay 8: Handheld Halting\nMy day 8 data\nPart 1: Infinite Loop\nOur programme gets stuck in an infinite loop. As well as keeping track of the accumulator, we need to keep track of where we’ve visited, and stop when we visit the same instruction twice. We use a data.frame() rather than a tibble() as the former is easier to index into.\n\n\ninstructions <- \n  read.table(\"data/AoC_day8.txt\", col.names = c(\"instruction\", \"value\"))\n\n\n\nWe start with a pretty straight-forward loop, noting that at most it can run for one more than the number of instructions in the programme until it hits an instruction it’s already visited. We update row number to visit next and the accumulator as appropriate.\n\n\ninstructions$visited <- 0\n\nrow <- 1\naccumulator <- 0\n\nnum_rows <- nrow(instructions)\n\nfor (i in 1:(num_rows+1)) {\n\n  if (instructions[row, \"visited\"] != 0) break\n  \n  # +1 on number of times the row is visited\n  instructions[row, \"visited\"] <- instructions[row, \"visited\"] + 1\n\n  # case when the instruction is \"acc\"\n  if (instructions[row, \"instruction\"] == \"acc\") {\n    accumulator <- accumulator + instructions[row, \"value\"]\n    row <- row + 1\n  }\n  \n  # case when the instruction is \"jmp\"\n  else if (instructions[row, \"instruction\"] == \"jmp\") {\n    row <- row + instructions[row, \"value\"]\n  }\n\n  # case when the instruction is \"nop\"\n  else if (instructions[row, \"instruction\"] == \"nop\") {\n    row <- row + 1\n  }\n}\n  \naccumulator\n\n\n[1] 1915\n\nPart 2: Fixing the programme\nTo break the loop, one of the nop instructions in the programme should be a jmp or vice versa. The plan is to swap these out one by one and check if the programme completes. It’s not a sophisticated approach, but it works fast enough (about a second).\nFirst we note that the broken instruction must be one that we visited in Part 1. Also, an instruction of jmp with a value of 0 will get us stuck in a one-line infinite loop, so we avoid that.\n\n\nlibrary(dplyr)\n\nrows_to_check <- instructions %>%\n  mutate(row_id = row_number()) %>%\n  filter(visited != 0) %>%\n  filter(instruction != \"acc\") %>%\n  filter(!(instruction == \"nop\" & value == 0)) %>%\n  pull(row_id)\n\n\n\nWe have 93 instruction to check. We modify our code from Part 1 slightly, converting it into a function and returning a list with values completes and accumulator. completes is FALSE as soon as we visit a row twice and TRUE if the number of our next row to visit is greater than the number of rows in the programme.\n\n\nprogramme_completes <- function(instructions) {\n  \n  row <- 1L\n  accumulator <- 0\n  \n  num_rows <- nrow(instructions)\n  \n  for (i in 1:(num_rows+1)) {\n  \n    if (instructions[row, \"visited\"] != 0) {\n      return(list(completes = FALSE, accumulator = accumulator)) \n    }\n    \n    # +1 on number of times the row is visited\n    instructions[row, \"visited\"] <- instructions[row, \"visited\"] + 1\n  \n    # case when the instruction is \"acc\"\n    if (instructions[row, \"instruction\"] == \"acc\") {\n      accumulator <- accumulator + instructions[row, \"value\"]\n      row <- row + 1\n    }\n  \n    else if (instructions[row, \"instruction\"] == \"jmp\") {\n      row <- row + instructions[row, \"value\"]\n    }\n  \n    else if (instructions[row, \"instruction\"] == \"nop\") {\n      row <- row + 1\n    }\n  \n    if (row > num_rows) {\n      return(list(completes = TRUE, accumulator = accumulator)) \n    }\n  }\n}  \n\n\n\nWe now loop over the rows we’ve identified to check, breaking the loop as soon as we find a programme that completes. Finally, we extract the accumulator value from the successful programme.\n\n\ninstructions$visited <- 0\n\nfor (row in rows_to_check) {\n  \n  # modify one row of the instructions,\n  # copying data frame so we don't have to modify it back\n  modified_instructions <- instructions\n  \n  ifelse(instructions[row, 1] == \"jmp\", \n         modified_instructions[row, 1] <- \"nop\", \n         modified_instructions[row, 1] <- \"jmp\") \n  \n  # check if the modified programme completes\n  check_programme <- programme_completes(modified_instructions)\n  \n  if (check_programme$completes) \n    break\n}\n\ncheck_programme$accumulator\n\n\n[1] 944\n\nDay 9: Encoding Error\nMy day 9 data\nPart 1: Weak Link\nWe have to find the first number in the list which is not the sum of a pair of different numbers in the preceding 25 numbers.\n\n\ninput <- as.double(readLines(\"data/AoC_day9.txt\")) \n\n\n\nThere’s a nice trick for finding the pair of numbers in a vector that sum to a target that was doing the rounds on twitter in response to the Day 1 challenge: intersect(input, 2020 - input). For this challenge, we expand on that idea, writing it as a check_sum function. Where there’s more than one pair, it won’t say which pair together, and if the number that’s half the target appears in the addends, it will only appear once in the output. However, for this challenge, we only need to know when there are no pairs that sum to the target, which will be the case when the length of the output of check_sum is 0.\n\n\ncheck_sum <- function(target, addends) {\n  intersect(addends, target-addends)\n}\n\n\n\nThen, it’s simply a case of iterating over windows of length 25, checking whether the following number is the sum of a distinct pair in that window, and returning the first one that isn’t.\n\n\nfind_invalid_num <- function(vec, win = 25) {\n  \n  for (i in (win+1):length(vec)) {\n    check <- check_sum(vec[i], vec[(i-win):(i-1)])\n    \n    if (length(check) == 0) return(vec[i])\n  }\n  \n}\n\nfind_invalid_num(input)\n\n\n[1] 507622668\n\nPart 2: Contiguous set\nFind a contiguous set in the list that sums to the invalid number from Part 1, and add together the largest and smallest number in that range.\nFirst, we note that after a certain point, all numbers in the input are larger than the target, so we don’t need to consider those. We reduce our input vector accordingly.\n\n\ntarget <- find_invalid_num(input)\n\ninput_reduced <- input[1:(max(which(input <= target)))]\n\n\n\nTo find the contiguous set in the list that sums to the target, we make use of accumulate() from the purrr package. Let the input list be \\(x = (x_1, x_2,..., x_n)\\). Then accumulate(x, sum) returns \\(a = (x_1, x_1 + x_2,..., \\sum_{j=1}^n x_j)\\). We check whether any element of this vector is equal to the target. If so we index into the input vector appropriately, sum the min and max in the range and we’re done. If not, we consider the sums of all windows starting with the second element of the input list, and so on.\n\n\ncontiguous_sum <- function(input, target) {\n  \n  len <- length(input)\n  \n  for (i in 1:len) {\n    a <- purrr::accumulate(input[i:len], sum)\n    b <- a == target\n    \n    if (sum(b) == 1) {\n      output_length <- which(b)\n      \n      contiguous_set <- input[i:(i + output_length - 1)]\n      \n      return(sum(range(contiguous_set)))\n    }\n  }\n}\n\ncontiguous_sum(input_reduced, target)\n\n\n[1] 76688505\n\nI appreciate that there’s some redundant calculation in this method. The vectors of accumulated sums can contain numbers larger than the target (if writing our own loop, we could break as soon as the accumulated sum got too big). Also, in retrospect, we could have only run accumulate once, then in the second iteration of the loop, subtracted input[1] from the result, in the third iteration subtracted input[2] from that result, etc. However, the function as written is concise and easy to understand, and gets our answer in around a second, so that will do!\nDay 10: Adapter Array\nMy day 10 data\nPart 1: Adapter Distribution\nThis is simply a case of ordering the adapters, prepending 0 and appending the the max in the list plus three, then finding the differences.\n\n\nlibrary(dplyr)\n\n\n\n\n\nadapters <- \n  readLines(\"data/AoC_day10.txt\") %>%\n  as.integer()\n\nadapter_diffs <- c(adapters, 0, max(adapters) + 3) %>% \n  sort() %>%\n  diff()\n\nsum(adapter_diffs == 1) * sum(adapter_diffs == 3)\n\n\n[1] 3034\n\nPart 2: Adapter combinations\nInstead of building up sequences of adapters, we see what we can remove from the full list.\nFirst, we check the diffs: are they just 1 and 3 or are there any 2s?\n\n\ntable(adapter_diffs)\n\n\nadapter_diffs\n 1  3 \n74 41 \n\nWe can’t remove an adapter if its difference with the previous adapter is 3, otherwise the difference between the adapters on either side of it will be too big.\nWhat about diffs of 1? It depends how many ones there are around it. We can check this using the rle() (run length encoding) function\n\n\nruns <- rle(adapter_diffs)\nruns\n\n\nRun Length Encoding\n  lengths: int [1:48] 3 2 4 2 4 2 4 1 4 2 ...\n  values : num [1:48] 1 3 1 3 1 3 1 3 1 3 ...\n\nWhat is the distribution of lengths of sequences of 1s?\n\n\nruns_table <- table(runs$lengths) \nruns_table\n\n\n\n 1  2  3  4 \n13 14 10 11 \n\nWe have at most four diffs of 1 in a row.\nWe need to check that if we remove an adapter, the new differences do not exceed 3. Example sequences really helped me figure out what’s going on here:\nIf the diff sequence is …, 3, 1, 3,… (e.g. adapters 1, 4, 5, 8)\n1 option to keep as is\nWe cannot remove any adapters\n1 option in total\n\nIf the diff sequence is …, 3, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 9)\n1 option to keep as is\n1 option to remove one adapter (e.g. the 5)\nwe cannot remove two adapters\n2 options total\n\nIf the diff sequence is …, 3, 1, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 7, 10)\n1 option to keep as is\n2 options to remove one adapter (e.g. the 5 or 6)\n1 options to remove two adapters (e.g. the 5 and 6)\nWe cannot remove three adapters\n4 options total\n\nIf the diff sequence is …, 3, 1, 1, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 7, 8, 11)\n1 option to keep as is\n3 options to remove one adapter (e.g. 5, 6, or 7)\n3 options to remove two adapters (e.g. any two of 5, 6, and 7)\nWe cannot remove three adapters\n7 options total\n\nFinally, we multiply each run length of difference of 1s with the number of options we have for removing adapters, then take the product of those products.\n\n\nruns_df <- tibble(lengths = runs$lengths, values = runs$values)\n\noptions <- tibble(lengths = c(1,2,3,4), options = c(1,2,4,7))\n\nruns_df %>%\n  filter(values == 1) %>%\n  left_join(options, by = \"lengths\") %>%\n  summarise(prod_options = prod(options)) %>%\n  pull(prod_options) %>%\n  format(scientific = FALSE) \n\n\n[1] \"259172170858496\"\n\nDay 11: Seating System\nMy day 11 data\nPart 1: Changing layout\nMy code for Day 11 runs a little slow (about 10 seconds for Part 1 and 80 seconds for Part 2), so for the sake of being able to rebuild this page quickly as I keep updating it working through the challenges, I will demonstrate this code with the test input provided as an example.\n\n\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(tidyr)\n\n\n\nFirst we read in the data and convert it to a matrix (using the datapasta package for the test input):\n\n\n# layout <- readr::read_tsv(\"data/AoC_day11.txt\", col_names = FALSE)\n\nlayout <- tibble::tribble(\n  ~X1,\n  \"L.LL.LL.LL\",\n  \"LLLLLLL.LL\",\n  \"L.L.L..L..\",\n  \"LLLL.LL.LL\",\n  \"L.LL.LL.LL\",\n  \"L.LLLLL.LL\",\n  \"..L.L.....\",\n  \"LLLLLLLLLL\",\n  \"L.LLLLLL.L\",\n  \"L.LLLLL.LL\"\n  )\n\n\n\n\n\n# get number of columns for matrix\nnum_col <- layout %>%\n  mutate(length = str_length(X1)) %>%\n  slice(1) %>%\n  pull(length)\n\n# split layout into characters and turn to vector\nlayout_vec <- layout %>%\n  mutate(X1 = strsplit(X1, split = character(0), fixed = TRUE)) %>%\n  pull(X1) %>%\n  unlist()\n\n# organise into matrix\ninitial_layout <- matrix(layout_vec, ncol = num_col, byrow = TRUE)\n\n\n\nNext, we write a helper function that, given a matrix and row and column indices, returns a vector of the adjacent seats. We need to take care when indexing into the matrix, so we treat all corner and edge cases separately. Fiddly, but gets the job done.\n\n\nget_adj <- function(mat, i,j) {\n  \n  nr <- nrow(mat)\n  nc <- ncol(mat)\n  \n  # corner cases\n  if (i == 1 & j == 1) {adj <- c(mat[1,2], mat[2,1:2])}\n  else if (i == 1 & j == nc) {adj <- c(mat[1,(nc-1)], mat[2,(nc-1):nc])}\n  else if (i == nr & j == 1) {adj <- c(mat[nr,2], mat[nr-1,1:2])}\n  else if (i == nr & j == nc) {adj <- c(mat[nr-1, (nc-1):nc], mat[nr, nc-1])}  \n  \n  # edge cases\n  else if (i == 1) {adj <- c(mat[1, c(j-1,j+1)], mat[2, (j-1):(j+1)])}\n  else if (i == nr) {adj <- c(mat[nr, c(j-1,j+1)], mat[nr-1, (j-1):(j+1)])}\n  else if (j == 1) {adj <- c(mat[c(i-1, i+1), 1], mat[(i-1):(i+1), 2])}\n  else if (j == nc) {adj <- c(mat[c(i-1, i+1), nc], mat[(i-1):(i+1), nc-1])}\n  \n  # inside cases\n  else {adj <- c(mat[i-1,(j-1):(j+1)], mat[i,c(j-1,j+1)], mat[i+1,(j-1):(j+1)])}\n  \n  adj\n}\n\n\n\nOnce we have a vector of surrounding seats, we can apply the rules in the problem to determine whether a given seat needs to change state. The needs_changing helper function does that. It’s overkill at this point to give options to specify the function for finding the vector of seats to check, and the maximum number of occupied seats people can tolerate around them, but (spolier alert) I put in these options when working on the challenge in Part 2.\n\n\nneeds_changing <- \n  function(mat, i,j, get_surround = get_adj, max_occupied = 4) {\n  \n  surround <- get_surround(mat, i,j)\n  n_occupied <- sum(surround == \"#\")\n  \n  if ((mat[i,j] == \"L\") & (n_occupied == 0)) return(TRUE)\n  \n  else if ((mat[i,j] == \"#\") & (n_occupied >= max_occupied)) {\n    return(TRUE)\n  }\n  \n  else return(FALSE)\n}\n\n\n\nSince floor spaces don’t change, we only need to consider seats. We save the indices of the seats into a data frame, so we can vectorise over it using tidyverse functions. However, when we’ve determined the seats that need changing, using our needs_changing function, we need to convert those indices from a data.frame into a matrix, in order to index into the layout matrix appropriately and make the changes.\n\n\nseats <- which(initial_layout != \".\", arr.ind = TRUE)\n\nseats_df <- as.data.frame(seats) %>%\n  rename(i = row, \n         j = col)\n\n\n\n\n\nlayout <- initial_layout\niters <- 0\n\n# loop until there are no further changes\nrepeat {\n  \n  change <- 0\n  \n  seats_to_change <- \n    seats_df %>%\n    rowwise() %>%\n    mutate(change_seat = needs_changing(layout,i,j))   \n  \n  change <- sum(seats_to_change$change_seat)\n  \n  if (change == 0) break\n  \n  indices_to_change <- \n    seats_to_change %>%\n    filter(change_seat) %>%\n    select(i,j) %>%\n    as.matrix()  \n\n  layout[indices_to_change] <- \n    setdiff(c(\"L\", \"#\"),  layout[indices_to_change])\n  \n  iters <- iters + 1\n}\n\npart_1_iters <- iters\nsum(layout== \"#\")\n\n\n[1] 37\n\nOn the test set, this takes 5 iterations. On the full data set, my answer is 2316, and it took 107 iterations.\nPart 2: Looking further\nNow, people look to the first seat they can see in each direction, and will change from occupied to unoccupied if five or more of them are occupied.\nThe plan is to write a function that extracts full vectors from a given seat to the edge of the layout matrix in each of the eight directions, then finds the first seat in each of those directions, and finally collects those into a vector of the seats under consideration when determining if a change is needed. Then I can reuse the loop from Part 1, just changing the arguments in the calls to needs_changing.\nHere’s a helper function to get the first seat in a vector looking in one direction:\n\n\nget_first_seat_from_vec <- function(vec) {\n  \n  if (any(vec %in% c(\"#\", \"L\"))) {\n    return(vec[min(which(vec != \".\"))])\n  }\n  \n  return(NA)\n}\n\n\n\nNow, if I thought getting adjacent seats to a given seat in Part 1 was fiddly, it’s nothing on getting a vector from a given seat to the edge of the matrix. There are many cases to consider to make we we don’t go out of bounds. In the diagonal directions, first we get a matrix of the indices of the matrix we need, then subset into the matrix accordingly.\n\n\n# takes a layout matrix (elements \".\", \"#\", \"L\")\n# returns vector with first \"L\" or \"#\" encountered in each direction\nget_first_seat <- function(mat, i,j) {\n  \n  nr <- nrow(mat)\n  nc <- ncol(mat)\n  \n  # North\n  if (i == 1) N <- NA\n  if (i > 1) N <- mat[(i-1):1,j]\n  \n  # South\n  if (i == nr) S <- NA\n  if (i < nr) S <- mat[(i+1):nr,j]\n  \n  # East\n  if (j == nc) E <- NA\n  if (j < nc) E <- mat[i, (j+1):nc]\n  \n  # West\n  if (j == 1) W <- NA\n  if (j > 1) W <- mat[i, (j-1):1]\n  \n  # how far in each direction to edge of matrix\n  to_N <- i - 1\n  to_S <- nr - i\n  to_E <- nc - j\n  to_W <- j - 1\n  \n  # North-West\n  NW_length <- min(to_N, to_W)\n  \n  if (i == 1 | j == 1) NW <- NA\n  else {\n    mat_index <- \n      matrix(c((i-1):(i-NW_length), (j-1):(j-NW_length)), ncol = 2)\n    NW <- mat[mat_index]\n  }\n  \n  # North-East\n  NE_length <- min(to_N, to_E)\n  \n  if (i == 1 | j == nc) NE <- NA\n  else {\n    mat_index <- \n      matrix(c((i-1):(i-NE_length), (j+1):(j+NE_length)), ncol = 2)\n    NE <- mat[mat_index]\n  }\n  \n  # South-East\n  SE_length <- min(to_S, to_E)\n  \n  if (i == nr | j == nc) SE <- NA\n  else {\n    mat_index <- \n      matrix(c((i+1):(i+SE_length), (j+1):(j+SE_length)), ncol = 2)\n    SE <- mat[mat_index]\n  }\n  \n  # South-West\n  SW_length <- min(to_S, to_W)\n  \n  if (i == nr | j == 1) SW <- NA\n  else {\n    mat_index <- \n      matrix(c((i+1):(i+SW_length), (j-1):(j-SW_length)), ncol = 2)\n    SW <- mat[mat_index]\n  }\n\n  # vectors from mat[i,j] to the edge in each direction \n  all_vecs <- \n    (list(N = N, S = S, E = E, W = W, NW = NW, NE = NE, SE = SE, SW = SW))\n  \n  # the first seat in each direction, collapsed to a vector\n  first_seats <- purrr::map_chr(all_vecs, get_first_seat_from_vec)\n  \n  # remove NAs from list and return\n  # (these occur either when starting on an edge, \n  # or when there are no seats in a given direction)\n  return(first_seats[!is.na(first_seats)])\n\n}\n\n\n\n\n\nlayout <- initial_layout\niters <- 0\n\n# loop until there are no further changes\nrepeat {\n  \n  change <- 0\n  \n  seats_to_change <- \n    seats_df %>%\n    rowwise() %>%\n    mutate(change_seat = needs_changing(layout,i,j, get_first_seat, 5))   \n  \n  change <- sum(seats_to_change$change_seat)\n  \n  if (change == 0) break\n  \n  indices_to_change <- \n    seats_to_change %>%\n    filter(change_seat) %>%\n    select(i,j) %>%\n    as.matrix()  \n\n  layout[indices_to_change] <- \n    setdiff(c(\"L\", \"#\"),  layout[indices_to_change])\n  \n  iters <- iters + 1\n}\n\npart_2_iters <- iters\nsum(layout== \"#\")\n\n\n[1] 26\n\nOn the test set, this takes 6 iterations. On the full data set, my answer is 2128, and it took 87 iterations. Given this is fewer iterations than in Part 1, it must be my code for getting the first seat that’s slowing things down.\nI am unsatisfied both by how many lines of code this has taken as well as the time taken to run. The introduction to Advent of Code says that each challenge has a solution that will complete in at most 15 seconds on ten year old hardware. So clearly there’s a better way of doing this. Perhaps something to revisit in the future.\nNext\nI was late to the game, and that was as far as I managed to get in December 2020. I’m looking forward to taking on the challenge again in 2021!\n\n\n\n",
    "preview": "posts/2020-12-09-advent-of-code-2020/advent-of-code-2020.jpg",
    "last_modified": "2021-05-26T15:20:26+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2017-06-17-n-letter-words/",
    "title": "n_letter_words and a personal (publicly available) package",
    "description": "How I created a handy function and a personal package",
    "author": [
      {
        "name": "Ella Kaye",
        "url": "https://twitter.com/ellamkaye"
      }
    ],
    "date": "2017-06-17",
    "categories": [
      "R functions",
      "R package development"
    ],
    "contents": "\nThere’s a little R function that I wrote and packaged up to generate a vector or data frame of words of a given length. I find it useful in a wide variety of contexts and thought other might too. To kick off my new blog, here’s a post about it.\nThe function, n_letter_words, came about because I wanted to be able to generate row and column names for a large matrix - didn’t matter what they were, as long as they were unique. Since I was in the habit of using the built-in LETTERS vector to do this for small matrices, I naturally thought of using combinations of letters to do this in a larger case. In figuring out how to do this, as is so often the case, it was stackoverflow to the rescue. There, I learnt about expand.grid and could then use some tidyverse tools to get the vector I was after:\n\n\nlibrary(tidyverse)\nout <- expand.grid(LETTERS, LETTERS) %>%\n  as_tibble() %>%\n  unite(word, 1:2, sep = \"\") %>%\n  pull()\nc(head(out), tail(out))\n\n\n [1] \"AA\" \"BA\" \"CA\" \"DA\" \"EA\" \"FA\" \"UZ\" \"VZ\" \"WZ\" \"XZ\" \"YZ\" \"ZZ\"\n\nSorted! At least I thought so, until, a couple of months later, when I wanted to generate names for a 1000*1000 matrix, and realised both that I’d forgotten the expand.grid trick, and once I’d re-found the stackoverflow post, that it didn’t give me enough words. That was enough to make it worth writing a function, taking n as an argument, that gives all ‘words’ of length \\(n\\).\nWriting functions always makes me think of what other arguments might be useful. What if we want something between the 676 two-letter words and 17,576 three-letter words (or the 456,976 four-letter words, etc)? Hence the argument num_letters, which can be set between 1 and 26, and results in a total of \\(\\text{num_letters}^n\\) words. By default, the function returns a tibble, but setting as_vector = TRUE does what you’d expect. And I threw in a case argument too.\nNow that I had my function, what to do with it? I remembered articles I’d read about the usefulness of making and sharing a personal package. Now seemed like the time to do that myself.\nSo, here is my personal package, EMK. If you think that n_letter_words might be of use to you, then feel free to install!\n\n\ndevtools::install_github(\"EllaKaye/EMK\")\n\n\n\nSome examples of n_letter_words:\n\n\nlibrary(EMK)\n\nn_letter_words(2)\n\n\n# A tibble: 676 x 1\n   word \n   <chr>\n 1 AA   \n 2 BA   \n 3 CA   \n 4 DA   \n 5 EA   \n 6 FA   \n 7 GA   \n 8 HA   \n 9 IA   \n10 JA   \n# … with 666 more rows\n\nsome_three_letter_words <- n_letter_words(\n  3, num_letters = 10, \n  case = \"lower\", \n  as_vector = TRUE\n)\n\nc(head(some_three_letter_words), tail(some_three_letter_words))\n\n\n [1] \"aaa\" \"baa\" \"caa\" \"daa\" \"eaa\" \"faa\" \"ejj\" \"fjj\" \"gjj\" \"hjj\" \"ijj\"\n[12] \"jjj\"\n\nlength(some_three_letter_words)\n\n\n[1] 1000\n\nFor now, my personal package has only this one function, but watch this space! No doubt I’ll be adding more that I find useful. Perhaps, you’ll find them useful too.\nIncidentally, none of the above would have happened if I’d just thought, for my test matrix A, to set dimnames(A) <- list(1:nrow(A), 1:ncol(A))!\n\n\n\n",
    "preview": "posts/2017-06-17-n-letter-words/EMK-hex.png",
    "last_modified": "2021-05-26T15:20:26+01:00",
    "input_file": {},
    "preview_width": 348,
    "preview_height": 400
  }
]
